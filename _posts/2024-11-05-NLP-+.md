---
layout: post
title: "NLP ì‹¬í™”ë°œì œ"
date: 2024-11-06
categories: NLP
---
# Full Fine-Tuning
* Fine-tuning ì¤‘ í•˜ë‚˜ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¬í•™ìŠµí•˜ì—¬ ìµœì í™”í•˜ëŠ” ê³¼ì •
* ëª¨ë¸ì˜ **ëª¨ë“  ê°€ì¤‘ì¹˜**ë¥¼ ì¡°ì •í•˜ëŠ” ë°©ì‹
* ë‹¨ì  : ë©”ëª¨ë¦¬ì™€ ê³„ì‚° ë¹„ìš©ì´ ë§¤ìš° ë§ì´ í•„ìš”

# Parameter-Efficient Fine-Tuning(PET)
* ìœ„ì˜ ë¹„ìš©ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ì‹
* ì „ì²´ ëª¨ë¸ì˜ **ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ** ì¡°ì •í•˜ê±°ë‚˜, ì¶”ê°€ì ì¸ ëª¨ë“ˆì„ ì¶”ê°€í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ fine-tuning í•˜ëŠ” ë°©ì‹   

## Adapter Tuning 
* adapterëŠ” ëŒ€í˜• ëª¨ë¸ì˜ ê° ë ˆì´ì–´ì— ì¶”ê°€ë˜ëŠ” ì‘ì€ ëª¨ë“ˆ
* ê¸°ì¡´ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ **Adapter ëª¨ë“ˆì˜ íŒŒë¼ë¯¸í„°(ì¶”ê°€íŒŒë¼ë¯¸í„°)ë§Œ** í•™ìŠµí•˜ëŠ” ë°©ì‹   
* **ì €ì°¨ì›**ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ í•™ìŠµ

![êµ¬ì¡°](/img/adapterêµ¬ì¡°.png)      
* ì˜¤ë¥¸ìª½:adapter, ì™¼ìª½: adapterë¥¼ transformerì— ì ìš© 
* Transformer ë ˆì´ì–´ì˜ Feed-forward ì¸µì´ë‚˜ ë ˆì´ì–´ ì •ê·œí™”(Layer Norm) ì§í›„ì— ì‚½ì…    

### êµ¬ì¡° 
1. Feedforward Up-Projection   
* ì…ë ¥ì„ ì €ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ëŠ” ì„ í˜• ë³€í™˜ ->  íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì„
2. Nonlinearity
* ì¼ë°˜ì ìœ¼ë¡œ ReLUì™€ ê°™ì€ ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ê°€ ì‚¬ìš©ëŒ
* ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€ -> ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµ
3. Feedforward Down-Projection  
* ì¶•ì†Œëœ ì°¨ì›ì„ ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì„ í˜• ë³€í™˜
* AdapterëŠ” í•„ìš”í•œ ì •ë³´ë¥¼ ì›ë˜ ì°¨ì›ìœ¼ë¡œ ë˜ëŒë ¤ Transformer ë ˆì´ì–´ì— ì „ë‹¬
* ìµœì¢… ì¶œë ¥ ì°¨ì›ì€ ì›ë˜ ì°¨ì›ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€   

#### Adapter ëª¨ë“ˆ ìš”ì†Œ 
1. Bottle-neck êµ¬ì¡°
* ëª©ì  : íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ 
* ì‘ë™ ë°©ì‹ :
    * ì²«ë²ˆì§¸ íˆ¬ì˜(projection): ì…ë ¥ ì°¨ì› d -> m, íŒŒë¦¬ë¯¸í„°ìˆ˜ëŠ” dmê°œ 
    * ë‘ë²ˆì§¸ íˆ¬ì˜(projection): m -> ì›ë˜ ì°¨ì› d, íŒŒë¼ë¯¸í„°ìˆ˜ëŠ” mdê°œ 
             
* ê° ë ˆì´ì–´ì— ì¶”ê°€ë˜ëŠ” ì´ íŒŒë¼ë¯¸í„° ìˆ˜ = 2md+d+m
* ì¼ë°˜ì ìœ¼ë¡œ mì€ ì „ì²´ ëª¨ë¸ ì°¨ì›ì˜ 0.5%~8% ë¡œ ì„¤ì • 
![ê·¸ë¦¼](/img/adapterbottle.png)    
2. Skip-Connection
* ëª©ì  : Adapter ì´ ì°¨ì› ì¶•ì†Œì™€ í™•ì¥ì„ í•˜ë”ë¼ë„ ì›ë˜ ì…ë ¥ì •ë³´ê°€ ì†ì‹¤ì—†ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ 
* ì—­í•  : ì›ë˜ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬ -> ì¶”ê°€ì ì¸ ì •ë³´ í•™ìŠµì´ ëª¨ë¸ì— í†µí•©ë˜ë„ë¡ ì—°ê²°              
![ê·¸ë¦¼](/img/adapterskio.png)

### ì„±ëŠ¥    
ë…¼ë¬¸ì—ì„œ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²ƒ ì¤‘ ì¼ë¶€   
![ì„±ëŠ¥](/img/adapterì„±ëŠ¥í‰ê°€.png)     
* xì¶• : ê°’ì´ í´ìˆ˜ë¡ ëª¨ë¸ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ë§ì•„ì§
* yì¶• : ì„±ëŠ¥ ë³€í™”, 0ì€ ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ê³¼ ë™ì¼í•œ ê²½ìš° 
* Adapter Tuning: 0ì— ê°€ê¹Œìš´ ìœ„ì¹˜ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ -> ì ì€ ìˆ˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¡œ ì„±ëŠ¥ì„ ìœ ì§€
* Fine-tune top layers : íŒŒë¼ë¯¸í„°ê°€ ì ì„ ë•Œ ì„±ëŠ¥ì´ í¬ê²Œ ë–¨ì–´ì§ -> íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¦ê°€í•˜ë©´ì„œ ì„±ëŠ¥ì´ ê°œì„      


## LoRA
* PET ì¤‘ í•˜ë‚˜ì¸ Low-Rank Adaptation
* ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°ì •
* ì €ì°¨ì› í–‰ë ¬ì„ ì¶”ê°€í•´ ëª¨ë¸ì„ ì¡°ì •í•¨ìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ì™€ ì—°ì‚° ìì›ì„ ì ˆì•½

### LoRA êµ¬ì¡°
![ê°œë…](/img/lora1.png)         
1. íŒŒë€ìƒ‰ : Pretrained Weights (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜)
* ì´ ê°€ì¤‘ì¹˜ëŠ” ëª¨ë¸ì´ ì²˜ìŒì— í•™ìŠµëœ ìƒíƒœë¡œ, í•™ìŠµ ì¤‘ì— **Freeze**ë˜ì–´ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„

2. ì£¼í™©ìƒ‰ : ì €ì°¨ì› í–‰ë ¬ A,B
* í•™ìŠµ ì‹œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶€ë¶„
* í–‰ë ¬ BëŠ” ì´ˆê¸°í™” ì‹œì— ê°’ì´ 0ìœ¼ë¡œ ì„¤ì •, AëŠ” í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ Ïƒ^2ì¸ ì •ê·œë¶„í¬ë¡œ ì´ˆê¸°í™”
* A,Bì˜ ì°¨ì›ì€ rë¡œ ë‚®ìŒ

3. foward pass
* ì…ë ¥ x(1Ã—dí–‰ë ¬)ê°€ ëª¨ë¸ë¡œ ë“¤ì–´ì˜¤ë©´, ê¸°ì¡´ì˜ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ W(dÃ—dí–‰ë ¬)ì™€ ê³±í•´ì§ -> ëª¨ë¸ì˜ ê¸°ë³¸ì˜ˆì¸¡(1Ã—dí–‰ë ¬)
* Î”W = BÃ—A, Î”Wxë¥¼ ê³„ì‚°
* ìµœì¢…ì¶œë ¥ h = Wx + (BÃ—A)x (1Ã—d í–‰ë ¬)ë¥¼ ë§Œë“¦

![êµ¬ì¡°](/img/loraë¹„êµ.png)

#### ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ Freezeí•˜ëŠ” ë°©ì‹
* ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬(ì˜ˆ: PyTorch, TensorFlow)ì—ì„œëŠ” ê°€ì¤‘ì¹˜ë¥¼ Freezeí•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì¡´ì¬
* "requires_grad" ì‚¬ìš©í•´ í•´ë‹¹ ê°€ì¤‘ì¹˜ê°€ í•™ìŠµ ì¤‘ì— ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šë„ë¡ í•¨

#### ì €ì°¨ì› í–‰ë ¬ Aì™€ Bì˜ ê²°ì • ë°©ì‹
* Bì˜ ì°¨ì›ì„ rÃ—d, Aì˜ ì°¨ì›ì„ dÃ—r
* ì°¨ì› rì´ ë‚®ì•„ì§€ë©´ ê³„ì‚° ë¹„ìš©ì´ ì¤„ì–´ë“¤ì§€ë§Œ, ë„ˆë¬´ ì‘ìœ¼ë©´ ì„±ëŠ¥ì´ ë–¨ì–´ì§
* ë…¼ë¬¸ì—ì„œëŠ” ì‹¤í—˜ì ìœ¼ë¡œ r ê°’ì„ ì„¤ì •í•¨

#### ì°¨ì›ì´ ì¤„ì–´ë“œëŠ” ì •ë„ 
d=4096, r=16 ìœ¼ë¡œ ê°€ì •ì‹œ     
W íŒŒë¼ë¯¸í„° ìˆ˜ : 4096 x 4096 = 16,777,216 ê°œ    
A, B íŒŒë¼ë¯¸í„° ìˆ˜ì˜ í•© : 4096x16(A) + 16x4096(B) = 65,536 + 65,536 = 131,072 ê°œ
-> íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì•½ 0.78%ë¡œ ì¤„ì–´ë“ ë‹¤.
-> ëª¨ë“  Layer ì— A,B ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ì„œ ì‹¤ì œì ìœ¼ë¡œëŠ” ë” ì¤„ì–´ë“ ë‹¤. 

### ì •í™•ë„ 
![ì •í™•ë„](/img/lora2.png)
ë…¼ë¬¸ì— ë‚˜ì˜¨ ì—¬ëŸ¬ ì •í™•ë„ ì‚¬ì§„ ì¤‘ í•˜ë‚˜ 
íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” LORA ê°€ ì ì€ë° ì •í™•ë„ëŠ” ê·¸ ì´ìƒì¸ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŒ       

### LoRAì˜ Transformer ì ìš©
Transformerì˜ ì–´ë–¤ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— LoRA ë¥¼ ì ìš©í•´ì•¼ ì„±ëŠ¥ì´ ë†’ì€ì§€ ì‹¤í—˜í•œ ê²°ê³¼     
![ê²°ê³¼](/img/loraparameters.png)      
* GPT-3 175B ëª¨ë¸ì˜ Self-Attention ëª¨ë“ˆ ë‚´ ê°€ì¤‘ì¹˜ë“¤ì— í…ŒìŠ¤íŠ¸ í•œ ê²°ê³¼ 
* Wqì™€ ğ‘Šğ‘£ë¥¼ í•¨ê»˜ ì¡°ì •í•˜ëŠ” ê²ƒì´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ   

### Optimal Rank r     
ìµœì ì˜ ì°¨ì› r ì°¾ëŠ” ì‹¤í—˜í•œ ê²°ê³¼ 
![ê²°ê³¼](/img/lorar.png)         
* Wq,Wk,ğ‘Šğ‘£,Woì— r ê°’ì„ 1, 2, 4, 8, 64ë¡œ ì„¤ì •í•´ì„œ LoRAë¥¼ ì ìš© 
* r=4ì—ì„œ ê°€ì¥ ë†’ì€ ì„±ëŠ¥     

#### subspace similarity between different r
-> ë‚®ì€ ë­í¬ì™€ ë†’ì€ ë­í¬ì—ì„œ í•™ìŠµëœ ì €ì°¨ì› ê³µê°„(subspace)ì´ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ë¥¼ í‰ê°€
-> ë‚®ì€ rì—ì„œë„ ì¶©ë¶„í•œ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íŒë‹¨
-> ë­í¬ r=8ì—ì„œ í•™ìŠµëœ í•˜ìœ„ ê³µê°„ê³¼ r=64ì—ì„œ í•™ìŠµëœ í•˜ìœ„ ê³µê°„ì´ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì¸ë‹¤ë©´, ë­í¬ê°€ ë†’ì•„ì ¸ë„ í•™ìŠµëœ ì •ë³´ì˜ ì°¨ì´ê°€ í¬ì§€ ì•ŠìŒ       
![ìœ ì‚¬ë„ê³µì‹](/img/loraìœ ì‚¬ë„.png)        
![íˆíŠ¸ë§µ](/img/loraheatmap.png)     
ì •ê·œí™”ëœ í•˜ìœ„ ê³µê°„ ìœ ì‚¬ë„(subspace similarity)ëŠ” Ï•(Ar=8,Ar=64,i,j)ë¡œ ì •ì˜ë˜ê³  ê°’ì´ 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ í•˜ìœ„ê³µê°„ì´ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§
* ë°ì„ ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ
* iì™€ jì˜ ê°’ì´ ì‘ì€ ë¶€ë¶„, ìƒìœ„ íŠ¹ì´ ë²¡í„°(ì¤‘ìš”ì •ë³´ë‹´ê³ ìˆëŠ” ë²¡í„°)ê°„ì˜ ìœ ì‚¬ë„ê°€ ë†’ìŒ
* iì™€ jì˜ ê°’ì´ í° ë¶€ë¶„, í•˜ìœ„ íŠ¹ì´ ë²¡í„°(ë…¸ì´ì¦ˆ,ë¶ˆí•„ìš”í•œì •ë³´ìˆëŠ” ë²¡í„°) ê°„ì˜ ìœ ì‚¬ë„ ë‚®ìŒ     

-> ë‚®ì€ ë­í¬ r=8ìœ¼ë¡œë„ ì¶©ë¶„í•œ ì •ë³´ ìœ ì§€       

### ì½”ë“œ 
```python
import torch
import torch.nn as nn

class LoRA(nn.Module):
    def __init__(self, input_dim, output_dim, rank):
        super(LoRA, self).__init__()
        
        # ê¸°ì¡´ì˜ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ W
        self.W = nn.Linear(input_dim, output_dim, bias=False)
        
        # Wì˜ íŒŒë¼ë¯¸í„°ë¥¼ Freeze 
        for param in self.W.parameters():
            param.requires_grad = False  # Wë¥¼ Freezeí•˜ì—¬ í•™ìŠµí•˜ì§€ ì•Šë„ë¡ ì„¤ì •
        
        # ì¶”ê°€ëœ ì €ì°¨ì› í–‰ë ¬ Aì™€ B
        self.A = nn.Parameter(torch.randn(input_dim, rank) * 0.01)  # ì‘ì€ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        self.B = nn.Parameter(torch.randn(rank, output_dim) * 0.01)
        
    def forward(self, x):
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ Wì™€ ì…ë ¥ xì˜ ê³±
        Wx = self.W(x)
        
        # ì €ì°¨ì› í–‰ë ¬ Aì™€ Bì˜ ê³±ì„ ì¶”ê°€í•˜ì—¬ Î”Wë¥¼ ê³„ì‚°
        delta_Wx = x @ self.A @ self.B
        
        # ìµœì¢… ì¶œë ¥: Wx + Î”Wx 
        return Wx + delta_Wx

# ì˜ˆì‹œ: ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì›ì„ ì§€ì •í•˜ì—¬ ëª¨ë¸ ë§Œë“œëŠ” ê³¼ì •
input_dim = 768  # ì˜ˆ: ì…ë ¥ ì°¨ì›
output_dim = 768  # ì˜ˆ: ì¶œë ¥ ì°¨ì›
rank = 4  # ì €ì°¨ì› í¬ê¸°

model = LoRA(input_dim, output_dim, rank)
```
## QLoRA
* Quantized LoRAë¡œ LoRAì˜ íš¨ìœ¨ì„±ì„ ë”ìš± ë†’ì´ê¸° ìœ„í•´ **ì–‘ìí™”(Quantization)**ë¥¼ ì ìš©í•œ ë°©ì‹   
* ì–‘ìí™” :  ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë‚˜ í™œì„±í™” ê°’ì„ ì €ì¥í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë¹„íŠ¸ ìˆ˜ë¥¼ ì¤„ì—¬ í‘œí˜„í•˜ëŠ” ë°©ë²•      
-> ìˆ«ìì˜ í‘œí˜„ ì •ë°€ë„ë¥¼ ë‚®ì¶”ì–´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ì—°ì‚°ì„ íš¨ìœ¨í™”   
-> 32ë¹„íŠ¸ ë¶€ë™ ì†Œìˆ˜ì (floating point)ì—ì„œ  8ë¹„íŠ¸ ì •ìˆ˜(integer) ë˜ëŠ” 4ë¹„íŠ¸ ì •ìˆ˜ë¡œ í‘œí˜„      

### êµ¬ì¡°
![ê·¸ë¦¼](/img/qlora1.png)        
* 4-bit NormalFloat Quantization
    * NF4ëŠ” ë¶€ë™ì†Œìˆ˜ì  ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ 4ë¹„íŠ¸ í‘œí˜„
    * ì •ê·œ ë¶„í¬(ì •ê·œí™”ëœ ë¶„í¬)ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°ì—ì„œ ìµœì 
    -> ë¶„í¬ì˜ ì¤‘ì‹¬ê³¼ ë°€ì§‘ëœ ê°’ì„ ë” ì˜ í‘œí˜„í• 
    * Base Modelì´ 4-bit Transformerë¡œ í‘œì‹œëœ ë¶€ë¶„
    * ìˆ˜ì‹
     ![ìˆ˜ì‹](/img/qloraì–‘ìí™”1.png)    
        * qi: ì–‘ìí™”ëœ ê°’
        * Qx: ì–‘ìí™” í•¨ìˆ˜, ì…ë ¥ëœ ê°’ì„ ì •í•´ì§„ ì–‘ìí™” ë²”ìœ„ ë‚´ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ ë§¤í•‘
        * i,k: ì¸ë±ìŠ¤ ê°’ê³¼ ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°
* Double Quantization
    * ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì–‘ìí™”ëœ í›„ ì €ì¥ëœ ì–‘ìí™” ìƒìˆ˜(ì¼ë°˜ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë‚˜ ì˜¤í”„ì…‹)ë¥¼ ë‹¤ì‹œ ì–‘ìí™”
    * ì´ì¤‘ ì–‘ìí™”ë¥¼ í†µí•´ í•„ìš”í•œ ë©”ëª¨ë¦¬ë¥¼ í¬ê²Œ ì¤„ì„
* Paged Optimizers
    * ë¯¸ë‹ˆ ë°°ì¹˜ ê¸°ë°˜ í•™ìŠµ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬ ë¬¸ì œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬ 
    (ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ GPU ë©”ëª¨ë¦¬ê°€ ë¹ ë¥´ê²Œ ì°¸)
    * NVIDIAì˜ í†µí•© ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬, ìì£¼ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ GPUì—ì„œ CPU ë©”ëª¨ë¦¬ë¡œ ì´ë™ì‹œí‚¤ê³ , í•„ìš” ì‹œ ë‹¤ì‹œ GPUë¡œ ì´ë™
    * Paging Flow(ë¶„í™ìƒ‰ í™”ì‚´í‘œ)

### ìˆ˜ì‹
* QLoRAì—ì„œ ë‹¨ì¼ ì„ í˜• ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ê³„ì‚°
![ìˆ˜ì‹](/img/qloraìˆ˜ì‹1.png)     
    * Xbf16: BF16 í˜•ì‹ìœ¼ë¡œ í‘œí˜„ëœ ì…ë ¥ ë°ì´í„°
    * doubleDequant: ì´ì¤‘ ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ë¥¼ BF16 í˜•ì‹ìœ¼ë¡œ ë³µì› 
        * ì…ë ¥ê°’ì€ ì´ì¤‘ì–‘ìí™”ì—ì„œ ì‚¬ìš©ëœ ë§¤ê°œë³€ìˆ˜ì™€ ê°€ì¤‘ì¹˜ 
    * L:BF16 í˜•ì‹ìœ¼ë¡œ í‘œí˜„ëœ LoRA ì–´ëŒ‘í„° í–‰ë ¬              
-> â€‹ì´ì¤‘ ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ë¥¼ ë³µì›í•˜ê³ , ì…ë ¥ê°’ê³¼ LoRA ì–´ëŒ‘í„°ë¥¼ ì ìš©í•˜ì—¬ ìµœì¢… ì¶œë ¥ì„ ê³„ì‚°
 
* ë¹„ì–‘ìí™”(dequantization)
![ìˆ˜ì‹](/img/qloraìˆ˜ì‹2.png)      
  * ì›ë˜ í˜•ì‹ìœ¼ë¡œ ë³µì›(dequantize)í•´ì•¼ í•˜ë¯€ë¡œ, ì € ìˆ˜ì‹ì—ì„œëŠ” ë‘ ë²ˆì˜ ë¹„ì–‘ìí™” ê³¼ì •ì„ ìˆ˜í–‰
  * ì²«ë²ˆì§¸ ë¹„ì–‘ìí™” : 4ë¹„íŠ¸ ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ë¥¼ í’€ì–´ë‚´ê¸° ìœ„í•œ ìŠ¤ì¼€ì¼ë§ ê°’ì„ ê³„ì‚°      
  * ë‘ë²ˆì§¸ ë¹„ì–‘ìí™” : ì²« ë²ˆì§¸ ë¹„ì–‘ìí™” ê²°ê³¼ë¥¼ ì´ìš©í•´ ìµœì¢…ì ìœ¼ë¡œ BF16 í˜•ì‹ìœ¼ë¡œ ë³µì›        

### ì„±ëŠ¥
<img src="https://github.com/riverblue72/riverblue72.github.io/blob/main/img/qloraì„±ëŠ¥1.png?raw=true" alt="ì„±ëŠ¥" width="280" height="300">
 
* QLoRA-All, QLoRA-FFN, QLoRA-Attention : ëª¨ë“  ë ˆì´ì–´, FFN ë ˆì´ì–´, ì–´í…ì…˜ ë ˆì´ì–´ì— QLoRAë¥¼ ì ìš©í•œ ê²°ê³¼
* **Alpaca (ours)** :  QLoRAë¥¼ ì‚¬ìš©í•˜ì—¬ Alpaca ë°ì´í„°ì…‹ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸
* Stanford-Alpaca: 16ë¹„íŠ¸ë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ê¸°ì¡´ Stanford ëª¨ë¸
* QLoRA-All, QLoRA-FFN, QLoRA-Attention ëª¨ë‘ 16ë¹„íŠ¸ì˜ Stanford-Alpacaì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„

![ì„±ëŠ¥](/img/qloraì„±ëŠ¥2.png)    
* NF4 + DQê°€ ë†’ì€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ í•¨ê»˜ ë‹¤ë¥¸ ì–‘ìí™” ë°©ë²•ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ê·¸ ì´ìƒì˜ ì„±ëŠ¥ ë³´ì„

### ì½”ë“œ 
```python
pip install transformers
pip install accelerate
pip install bitsandbytes

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments
from transformers import BitsAndBytesConfig
from datasets import load_dataset

# 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
model_name = "facebook/opt-6.7b"  
# í•™ìŠµí•  ëª¨ë¸ ì´ë¦„
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 2. 4ë¹„íŠ¸ ì–‘ìí™” êµ¬ì„± ì„¤ì •
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,  # 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
    bnb_4bit_use_double_quant=True,  # ì´ì¤‘ ì–‘ìí™” ì ìš© (ë” ë‚˜ì€ ì„±ëŠ¥)
    bnb_4bit_quant_type="nf4",       # ì–‘ìí™” ìœ í˜• ì„ íƒ (ì¼ë°˜ì ìœ¼ë¡œ `nf4`ê°€ ì¢‹ìŒ)
    bnb_4bit_compute_dtype=torch.float16  # ê³„ì‚°ì‹œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ìœ í˜•
)

# 3. QLoRAë¥¼ ìœ„í•œ ëª¨ë¸ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,  # ì–‘ìí™” ì„¤ì • ì ìš©
    device_map="auto"  # GPU ìì› ìë™ìœ¼ë¡œ í• ë‹¹
)

# 4. ë°ì´í„°ì…‹ ì¤€ë¹„
dataset = load_dataset("wikitext", "wikitext-2-raw-v1", split="train")
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_dataset = dataset.map(tokenize_function, batched=True)

# 5. í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./qlora_model",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    warmup_steps=100,
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,  # 16-bit ë¶€ë™ ì†Œìˆ˜ì  ì‚¬ìš©
    logging_steps=10,
)

# 6. Trainer ì´ˆê¸°í™”
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
)

# 7. í•™ìŠµ ì‹œì‘
trainer.train()
```


### Reference
[Adapter paper](https://arxiv.org/pdf/1902.00751)    
[LoRA paper](https://arxiv.org/abs/2106.09685)     
[QLoRA paper](https://arxiv.org/abs/2305.14314)         
