---
layout: post
title: "NLP 3주차: mlp 모델로 이름 생성"
date: 2024-10-02
categories: NLP
---

# mlp model
Multi-Layer Perceptron 로 인공신경망의 한 종류이다. 입력층-은닉층-출력층으로 이뤄진다. 
![개념](/img/mlp개념.png)              

## 전체 개요
입력데이터 mlp 전달 → 입력데이터를 입력층, 은닉층, 출력층으로 전달 : 각층의 뉴런은 활성화함수를 적용해 다음 층으로 전달 → 손실계산 → 가중치 업데이트 하면서 최적화

### 데이터 준비 
#### 단어 사전 만들기
```python
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
%matplotlib inline

# 이름 데이터 
words = open('names.txt', 'r').read().splitlines() 

# build the vocabulary of characters and mappings to/from integers
chars = sorted(list(set(''.join(words))))
stoi = {s:i+1 for i,s in enumerate(chars)}
stoi['.'] = 0
itos = {i:s for s,i in stoi.items()}
```   
itos = { 0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f',,,,, } 이런 꼴     

#### 데이터셋 만들기 
```python
block_size = 3     # 앞 3글자 보고 뒤에 알파벳 예측할거임

def build_dataset(words):
  X, Y = [], []
  for w in words:           # words[0], emma 한다고 가정 

    context = [0] * block_size      # [0 0 0]
    for ch in w + '.':    # emma. 에서 for 문 사용
      ix = stoi[ch]     # emma. 알파벳에 해당하는 인덱스 
      X.append(context)     # [0 0 0] 추가 
      Y.append(ix)    # emma. 에 해당하는 인덱스 저장
      print(''.join(itos[i] for i in context), '--->', itos[ix])  
      context = context[1:] + [ix]  # [0 0]+[e에 해당하는 인덱스] = [0 0 5]

  X = torch.tensor(X)    # 입력데이터
  Y = torch.tensor(Y)    # 타깃데이터

  return X, Y
```    

emma. 만 살펴봤을때의 결과, 왼쪽 위:X 왼쪽아래:Y
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        .container {
            display: flex;
            align-items: flex-start;
        }
        .left {
            flex-basis: auto;
        }
        .right {
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }
        img {
            max-width: 100%;
            height: auto;
        }
        .right img {
            flex-grow: 1;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="left">
            <img src="https://github.com/riverblue72/riverblue72.github.io/blob/main/img/mlp첫번째프린트.png?raw=true" alt="1st Image">
        </div>
        <div class="right">
            <img src="https://github.com/riverblue72/riverblue72.github.io/blob/main/img/mlp에서X값.png?raw=true" alt="2nd Image" width = "200" >
            <img src="https://github.com/riverblue72/riverblue72.github.io/blob/main/img/mlp에서Y값.png?raw=true" alt="3rd Image" width = "250">
        </div>
    </div>
</body>
</html>

#### 훈련세트, 검증세트, 테스트 세트로 분할   
검증세트는 파라미터 조정하면서 사용한다. 과대적합을 방지하기 위해 테스트 세트는 최대한 적게 사용해야한다. 비율은 80 10 10 이다. 
``` python
import random
random.seed(42)
random.shuffle(words)
n1 = int(0.8*len(words))
n2 = int(0.9*len(words))

Xtr, Ytr = build_dataset(words[:n1])   # train set
Xdev, Ydev = build_dataset(words[n1:n2])  # validation set
Xte, Yte = build_dataset(words[n2:])  # test set 
```

### 모델 초기화  
``` python
g = torch.Generator().manual_seed(2147483647)   
C = torch.randn((27, 10), generator=g)
W1 = torch.randn((30, 200), generator=g)
b1 = torch.randn(200, generator=g)
W2 = torch.randn((200, 27), generator=g)
b2 = torch.randn(27, generator=g)
parameters = [C, W1, b1, W2, b2]

for p in parameters:
  p.requires_grad = True

```
#### 1. 임베딩행렬 C  
C 의 크기는 (27,10)이다. 27개의 문자가 10차원의 벡터로 변환된다.             
a = [0.1, -0.2, 0.7, 0.5, 0.3, -0.1, 0.4, 0.6, 0.8, -0.5] 처럼 무작위로 만드는 것이다. C[0]:., C[1]:a, C[2]:b ,,,,에 해당한다.      
처음에는 무작위지만 학습하면서 최적화된다. 문자간 유사성이나 의미적관계가 반영될 수 있다. a와 b가 자주 같이 등장한다면, 그 두 문자의 임베딩 벡터는 비슷해진다. 즉 거리가 가까워진다.  

#### 2. 첫 번째 가중치 행렬 W1와 편향 b1 
현재 입력층은 30차원이다. 3개의 문자를 각 10차원으로 임베팅하기 떄문에 3*10 차원이다. 
W1은 (30,200)으로 입력을 30차원에서 200차원으로 변환한다. → 200개의 은닉뉴런으로 변환     
b1은 크가 200으로 은닉층의 각 뉴런에 대응하는 편향값이다.      

#### 가중치 행렬의 역할? 
입력데이터를 변환해서 다음 층으로 전달한다.   
차원을 늘려서 복잡한 표현을 학습할 수 있게 한다. = 은닉뉴런이 많을 수록 많은 패턴 학습 가능    
#### 편향의 역할?     
가중치 계산에 더해지는 보정값으로 작용한다. 
뉴런의 출력값 = 입력값 * 가중치  + b  여서 뉴런의 유연한 학습을 도와 준다. 뉴런의 활성화되는 기준을 조정하고 결정경계를 이동시켜 복잡한 문제를 풀 수 있게 한다.    

#### 3. 두 번째 가중치 행렬 W2와 편향 b2
W2 은닉층의 출력(200차원)을 출력층으로 변환한다. 200은 은닉층의 출력차원 27은 출력차원이다. 
27개로 변환후 b2가 더해진다.  


### 학습과정

``` python
lre = torch.linspace(-3, 0, 1000)  # -3에서 0 구간 1000개로 나눔      
lrs = 10**lre   # 10^-3에서 10^0까지 생성       

lri = []
lossi = []
stepi = []


for i in range(1000):
  
  # minibatch construct
  # 무작위로 32개 가져온 인덱스 값
  ix = torch.randint(0, Xtr.shape[0], (32,))  
  

  # forward pass
  emb = C[Xtr[ix]]  # 임베딩벡터로 변환 
  # 활성화 함수로 비선형성 추가 >>  은닉층의 출력
  h = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # 활성화 함수로 비선형성 추가 >>  은닉층의 출력
  logits = h @ W2 + b2   # 출력층 = 예측값
  # 손실함수 계산
  # 내부적으로 소프트맥스 사용함
  loss = F.cross_entropy(logits, Ytr[ix])


  # backward pass
  for p in parameters:
    #backward pass 에서 계산된 파라미터의 기울기(gradient)
    p.grad = None     
  loss.backward()  # 손실값 loss 기울기를 계산 
  
  # update
  lr = lrs[i]
  for p in parameters:
    # 파라미터의 현재 값 = 학습률 * 기ㄹ기 
    p.data += -lr * p.grad    # 가중치 업데이트 

  # track stats
  lri.append(lr)   # 학습률 저장
  lossi.append(loss.item())  # 손실값 저장

```
``` python
plt.plot(lri, lossi) 
```
![결과](/img/mlp학습률.png)       
적절한 학습률 lr = 0.1 이다.          


아래는 학습률을 0.1로 설정한 것이다. 
```python
lre = torch.linspace(-3, 0, 1000)
lrs = 10**lre

lri = []
lossi = []
stepi = []

for i in range(200000):
  
  # minibatch construct
  ix = torch.randint(0, Xtr.shape[0], (32,))
  
  # forward pass
  emb = C[Xtr[ix]] # (32, 3, 10)
  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 200)
  logits = h @ W2 + b2 # (32, 27)
  loss = F.cross_entropy(logits, Ytr[ix])
  
  # backward pass
  for p in parameters:
    p.grad = None
  loss.backward()
  
  # update
  lr = 0.1 if i < 100000 else 0.01
  for p in parameters:
    p.data += -lr * p.grad

  # track stats
  stepi.append(i)
  lossi.append(loss.log10().item())

plt.plot(stepi, lossi)
```
![그래프](/img/mlpstep에따른그래프.png)   
손실값 변동폭이 크다. 미니배치 학습의 특징일 수 있다.     
  

#### 훈련,테스트,검증세트의 손실값 계산
``` python
# 훈련세트  
emb = C[Xtr] # (32, 3, 2)
h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)
logits = h @ W2 + b2 # (32, 27)
losstr = F.cross_entropy(logits, Ytr)

# 검증세트 
emb = C[Xdev]
h = torch.tanh(emb.view(-1, 30) @ W1 + b1) 
logits = h @ W2 + b2 
lossdev= F.cross_entropy(logits, Ydev)

# 테스트세트
emb = C[Xte]
h = torch.tanh(emb.view(-1, 30) @ W1 + b1) 
logits = h @ W2 + b2 
losste = F.cross_entropy(logits, Yte)
```
훈련세트: 2.06 검증세트: 2.13 테스트세트:2.13 으로 바이그램보단 손실이 낮아졌다.        


### 임베딩 벡터 그래프로 확인해보기
```python
plt.figure(figsize=(8,8))
plt.scatter(C[:,0].data, C[:,1].data, s=200)
for i in range(C.shape[0]):
    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha="center", va="center", color='white')
plt.grid('minor')
```
![그래프](/img/mlpC.png)     
모음끼리 가까이 있다.     

### 최종: 이름 만들기 
# sample from the model

``` python
g = torch.Generator().manual_seed(2147483647 + 10)

for _ in range(20):
    
    out = []
    context = [0] * block_size 
    while True:
      emb = C[torch.tensor([context])] 
      h = torch.tanh(emb.view(1, -1) @ W1 + b1)
      logits = h @ W2 + b2
      probs = F.softmax(logits, dim=1)
      ix = torch.multinomial(probs, num_samples=1, generator=g).item()
      context = context[1:] + [ix]
      out.append(ix)
      if ix == 0:
        break
    
    print(''.join(itos[i] for i in out))
```
![결과](/img/mlp결과.png)        